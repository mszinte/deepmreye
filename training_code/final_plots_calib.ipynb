{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [\"sub-02\",\"sub-03\",\"sub-04\", \"sub-05\", \"sub-06\", \"sub-07\",\"sub-08\", \"sub-09\",\"sub-11\", \"sub-13\", \"sub-14\", \"sub-15\", \"sub-16\", \"sub-17\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject      task       model      mean   75_perc\n",
      "0  sub-02  fixation  pretrained  5.256241  6.885061\n",
      "1  sub-02   pursuit  pretrained  4.288809  5.481960\n",
      "2  sub-02  freeview  pretrained  4.147764  5.291535\n",
      "3  sub-02       all  pretrained  4.436713  5.585948\n",
      "4  sub-03  fixation  pretrained  5.427978  7.019215\n"
     ]
    }
   ],
   "source": [
    "# PRETRAINED MODEL \n",
    "\n",
    "# Define tasks\n",
    "tasks = ['fixation', 'pursuit', 'freeview', 'all']\n",
    "\n",
    "# Initialize list to store data rows\n",
    "results = []\n",
    "\n",
    "for subject in subjects:\n",
    "    for task in tasks:\n",
    "        # Load data for each run\n",
    "        ee_run_01 = pd.read_csv(\n",
    "            f\"/Users/sinakling/disks/meso_shared/deepmreye/derivatives/pp_data/{subject}/eyetracking/timeseries/{subject}_task-DeepMReyeCalib_subtask-{task}_run_01_ee_pretrained.tsv.gz\",\n",
    "            compression='gzip', delimiter='\\t')[['ee']].to_numpy()\n",
    "        \n",
    "        ee_run_02 = pd.read_csv(\n",
    "            f\"/Users/sinakling/disks/meso_shared/deepmreye/derivatives/pp_data/{subject}/eyetracking/timeseries/{subject}_task-DeepMReyeCalib_subtask-{task}_run_02_ee_pretrained.tsv.gz\",\n",
    "            compression='gzip', delimiter='\\t')[['ee']].to_numpy()\n",
    "        \n",
    "        ee_run_03 = pd.read_csv(\n",
    "            f\"/Users/sinakling/disks/meso_shared/deepmreye/derivatives/pp_data/{subject}/eyetracking/timeseries/{subject}_task-DeepMReyeCalib_subtask-{task}_run_03_ee_pretrained.tsv.gz\",\n",
    "            compression='gzip', delimiter='\\t')[['ee']].to_numpy()\n",
    "        \n",
    "        # Combine runs and compute statistics\n",
    "        all_ee = np.concatenate([ee_run_01, ee_run_02, ee_run_03])\n",
    "        mean_ee = np.mean(all_ee)\n",
    "        perc_ee = np.percentile(all_ee, 75)\n",
    "        \n",
    "        # Append result to the list\n",
    "        results.append({\n",
    "            'subject': subject,\n",
    "            'task': task,\n",
    "            'model': 'pretrained',\n",
    "            'mean': mean_ee,\n",
    "            '75_perc': perc_ee\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_ee = pd.DataFrame(results)\n",
    "\n",
    "# Optional: display or save\n",
    "print(df_ee.head())\n",
    "# df_ee.to_csv('ee_pretrained_summary.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALED MODEL \n",
    "\n",
    "# Define tasks\n",
    "tasks = ['fixation', 'pursuit', 'freeview', 'all']\n",
    "\n",
    "# Initialize list to store data rows\n",
    "scaled_results = []\n",
    "\n",
    "for subject in subjects:\n",
    "    for task in tasks:\n",
    "        # Load data for each run\n",
    "        ee_run_01 = pd.read_csv(\n",
    "            f\"/Users/sinakling/disks/meso_shared/deepmreye/derivatives/pp_data/{subject}/eyetracking/timeseries/{subject}_task-DeepMReyeCalib_subtask-{task}_run_01_ee_scaled.tsv.gz\",\n",
    "            compression='gzip', delimiter='\\t')[['ee']].to_numpy()\n",
    "        \n",
    "        ee_run_02 = pd.read_csv(\n",
    "            f\"/Users/sinakling/disks/meso_shared/deepmreye/derivatives/pp_data/{subject}/eyetracking/timeseries/{subject}_task-DeepMReyeCalib_subtask-{task}_run_02_ee_scaled.tsv.gz\",\n",
    "            compression='gzip', delimiter='\\t')[['ee']].to_numpy()\n",
    "        \n",
    "        ee_run_03 = pd.read_csv(\n",
    "            f\"/Users/sinakling/disks/meso_shared/deepmreye/derivatives/pp_data/{subject}/eyetracking/timeseries/{subject}_task-DeepMReyeCalib_subtask-{task}_run_03_ee_scaled.tsv.gz\",\n",
    "            compression='gzip', delimiter='\\t')[['ee']].to_numpy()\n",
    "        \n",
    "        # Combine runs and compute statistics\n",
    "        all_ee = np.concatenate([ee_run_01, ee_run_02, ee_run_03])\n",
    "        mean_ee = np.mean(all_ee)\n",
    "        perc_ee = np.percentile(all_ee, 75)\n",
    "        \n",
    "        # Append result to the list\n",
    "        scaled_results.append({\n",
    "            'subject': subject,\n",
    "            'task': task,\n",
    "            'model': 'scaled',\n",
    "            'mean': mean_ee,\n",
    "            '75_perc': perc_ee\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_trained = pd.DataFrame(scaled_results)\n",
    "\n",
    "# Concatenate\n",
    "df_ee = pd.concat([df_ee, df_trained], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINE TUNED MODEL \n",
    "\n",
    "# Define tasks\n",
    "tasks = ['fixation', 'pursuit', 'freeview', 'all']\n",
    "\n",
    "# Initialize list to store data rows\n",
    "calib_results = []\n",
    "\n",
    "for subject in subjects:\n",
    "    for task in tasks:\n",
    "        # Load data for each run\n",
    "        ee_run_01 = pd.read_csv(\n",
    "            f\"/Users/sinakling/disks/meso_shared/deepmreye/derivatives/pp_data/{subject}/eyetracking/timeseries/{subject}_task-DeepMReyeCalib_subtask-{task}_run_01_ee_no_interpol.tsv.gz\",\n",
    "            compression='gzip', delimiter='\\t')[['ee']].to_numpy()\n",
    "        \n",
    "        ee_run_02 = pd.read_csv(\n",
    "            f\"/Users/sinakling/disks/meso_shared/deepmreye/derivatives/pp_data/{subject}/eyetracking/timeseries/{subject}_task-DeepMReyeCalib_subtask-{task}_run_02_ee_no_interpol.tsv.gz\",\n",
    "            compression='gzip', delimiter='\\t')[['ee']].to_numpy()\n",
    "        \n",
    "        ee_run_03 = pd.read_csv(\n",
    "            f\"/Users/sinakling/disks/meso_shared/deepmreye/derivatives/pp_data/{subject}/eyetracking/timeseries/{subject}_task-DeepMReyeCalib_subtask-{task}_run_03_ee_no_interpol.tsv.gz\",\n",
    "            compression='gzip', delimiter='\\t')[['ee']].to_numpy()\n",
    "        \n",
    "        # Combine runs and compute statistics\n",
    "        all_ee = np.concatenate([ee_run_01, ee_run_02, ee_run_03])\n",
    "        mean_ee = np.mean(all_ee)\n",
    "        perc_ee = np.percentile(all_ee, 75)\n",
    "        \n",
    "        # Append result to the list\n",
    "        calib_results.append({\n",
    "            'subject': subject,\n",
    "            'task': task,\n",
    "            'model': 'pt_calib',\n",
    "            'mean': mean_ee,\n",
    "            '75_perc': perc_ee\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_calib = pd.DataFrame(calib_results)\n",
    "\n",
    "# Concatenate\n",
    "df_ee = pd.concat([df_ee, df_calib], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import permutation_test\n",
    "import pandas as pd\n",
    "\n",
    "def paired_permutation_tests(df, model_a, model_b):\n",
    "    \"\"\"\n",
    "    Run paired permutation tests between two models for each task.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with columns ['subject', 'task', 'model', 'mean']\n",
    "        model_a (str): Name of the first model\n",
    "        model_b (str): Name of the second model\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with task, p-value, and effect size (mean diff)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Group only by task\n",
    "    grouped = df.groupby('task')\n",
    "\n",
    "    for task, group in grouped:\n",
    "        # Filter to the two models of interest\n",
    "        group_filtered = group[group['model'].isin([model_a, model_b])]\n",
    "\n",
    "        # Pivot: subjects as rows, models as columns\n",
    "        pivoted = group_filtered.pivot(index='subject', columns='model', values='mean').dropna()\n",
    "\n",
    "        if pivoted.shape[0] < 2:\n",
    "            continue  # Not enough subjects with data for both models\n",
    "\n",
    "        a_values = pivoted[model_a].values\n",
    "        b_values = pivoted[model_b].values\n",
    "\n",
    "        # Paired permutation test on mean difference\n",
    "        result = permutation_test(\n",
    "            (a_values, b_values),\n",
    "            statistic=lambda x, y: (x - y).mean(),\n",
    "            permutation_type='samples',\n",
    "            vectorized=False,\n",
    "            alternative='two-sided',\n",
    "            n_resamples=10000\n",
    "        )\n",
    "\n",
    "        results.append({\n",
    "            'task': task,\n",
    "            'model_a': model_a,\n",
    "            'model_b': model_b,\n",
    "            'mean_diff': (a_values - b_values).mean(),\n",
    "            'p_value': result.pvalue,\n",
    "            'n_subjects': len(pivoted)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        task     model_a   model_b  mean_diff   p_value  n_subjects\n",
      "0        all  pretrained    scaled   0.248655  0.002000          14\n",
      "1   fixation  pretrained    scaled   0.656068  0.000200          14\n",
      "2   freeview  pretrained    scaled  -0.123212  0.187181          14\n",
      "3    pursuit  pretrained    scaled   0.283770  0.001800          14\n",
      "4        all  pretrained  pt_calib   0.507080  0.000200          14\n",
      "5   fixation  pretrained  pt_calib   1.151713  0.000200          14\n",
      "6   freeview  pretrained  pt_calib   0.147515  0.131787          14\n",
      "7    pursuit  pretrained  pt_calib   0.404555  0.000200          14\n",
      "8        all      scaled  pt_calib   0.258425  0.001800          14\n",
      "9   fixation      scaled  pt_calib   0.495645  0.000400          14\n",
      "10  freeview      scaled  pt_calib   0.270727  0.018398          14\n",
      "11   pursuit      scaled  pt_calib   0.120785  0.073793          14\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run paired permutation tests \n",
    "\n",
    "sig_df_pt_vs_scaled = paired_permutation_tests(df_ee, model_a='pretrained', model_b='scaled')\n",
    "\n",
    "# Run paired permutation tests for another pairing (e.g., pt vs pt_gaze) and append to the same dataframe\n",
    "sig_df_pt_vs_calib = paired_permutation_tests(df_ee, model_a='pretrained', model_b='pt_calib')\n",
    "\n",
    "sig_df_scaled_vs_calib = paired_permutation_tests(df_ee, model_a='scaled', model_b='pt_calib')\n",
    "\n",
    "# Append the results from both pairings\n",
    "sig_df = pd.concat([sig_df_pt_vs_scaled, sig_df_pt_vs_calib, sig_df_scaled_vs_calib], ignore_index=True)\n",
    "\n",
    "# Show the combined dataframe with the significance results\n",
    "print(sig_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "# Define color and name mappings\n",
    "model_name_map = {\n",
    "    \"pretrained\": \"DeepMreye\",\n",
    "    \"scaled\": \"DeepMreye Scaled\",\n",
    "    \"pt_calib\": \"DeepMreye + Calib\"\n",
    "}\n",
    "\n",
    "bar_color = 'rgba(66, 129, 164, 0.25)' \n",
    "\n",
    "colormap_subject_dict = {\n",
    "    'sub-01': '#AA0DFE', 'sub-02': '#3283FE', 'sub-03': '#85660D', 'sub-04': '#782AB6',\n",
    "    'sub-05': '#565656', 'sub-06': '#1C8356', 'sub-07': '#16FF32', 'sub-08': '#F7E1A0',\n",
    "    'sub-09': '#E2E2E2', 'sub-11': '#1CBE4F', 'sub-13': '#DEA0FD', 'sub-14': '#FBE426', \n",
    "    'sub-15': '#325A9B', 'sub-16': '#FEAF16', 'sub-17': '#F8A19F'\n",
    "}\n",
    "\n",
    "task_labels = [\"<b>Guided Fixation<b>\", \"<b>Smooth Pursuit<b>\", \"<b>Freeviewing<b>\"]\n",
    "task_names = [\"fixation\", \"pursuit\", \"freeview\", \"all\"]\n",
    "\n",
    "\n",
    "comparisons = [\n",
    "    (\"pretrained\", \"scaled\"),\n",
    "    (\"pretrained\", \"pt_calib\"),\n",
    "    (\"scaled\", \"pt_calib\")\n",
    "]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=4, cols=3,\n",
    "    subplot_titles=[f\"{label}\" for label in task_labels for _ in range(3)] + [\"<b>All Tasks<b>\"] * 3\n",
    ")\n",
    "\n",
    "\n",
    "# Keep track of subjects already shown in legend\n",
    "shown_subjects = set()\n",
    "\n",
    "for i, task in enumerate(task_names):\n",
    "    for j, (model_a, model_b) in enumerate(comparisons):\n",
    "        row = i + 1\n",
    "        col = j + 1\n",
    "\n",
    "        df_plot = df_ee[\n",
    "            (df_ee[\"task\"] == task) &\n",
    "            (df_ee[\"model\"].isin([model_a, model_b]))\n",
    "        ]\n",
    "\n",
    "        df_pivot = df_plot.pivot(index=\"subject\", columns=\"model\", values=\"mean\")[[model_a, model_b]].dropna()\n",
    "\n",
    "        means = df_pivot.mean()\n",
    "        stderrs = df_pivot.sem()\n",
    "        x_vals = [0, 1]\n",
    "\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=x_vals,\n",
    "            y=means.values,\n",
    "            error_y=dict(type=\"data\", array=stderrs.values),\n",
    "            marker_color=bar_color,\n",
    "            width=0.25,\n",
    "            showlegend=False\n",
    "        ), row=row, col=col)\n",
    "\n",
    "        # Add connecting lines per subject\n",
    "        for subject, row_data in df_pivot.iterrows():\n",
    "            color = colormap_subject_dict.get(subject, 'gray')\n",
    "            show_legend = subject not in shown_subjects\n",
    "            shown_subjects.add(subject)\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x_vals,\n",
    "                y=row_data.values,\n",
    "                mode='lines+markers',\n",
    "                line=dict(color=color, width=1.5),\n",
    "                marker=dict(size=4),\n",
    "                name=subject,\n",
    "                opacity=0.9,\n",
    "                showlegend=show_legend\n",
    "            ), row=row, col=col)\n",
    "\n",
    "        # Add significance marker if p < 0.05\n",
    "        sig_row = sig_df[\n",
    "            (sig_df.task == task) &\n",
    "            (sig_df.model_a == model_a) &\n",
    "            (sig_df.model_b == model_b)\n",
    "        ]\n",
    "\n",
    "        if not sig_row.empty and sig_row.iloc[0].p_value < 0.05:\n",
    "            y_vals = means.values\n",
    "            max_y = max(y_vals)\n",
    "            line_y = max_y + 0.5\n",
    "\n",
    "            fig.add_shape(\n",
    "                type=\"line\",\n",
    "                x0=0,\n",
    "                x1=1,\n",
    "                y0=line_y,\n",
    "                y1=line_y,\n",
    "                line=dict(color=\"black\", width=1),\n",
    "                row=row, col=col\n",
    "            )\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[0.5],\n",
    "                y=[line_y + 1],\n",
    "                text=[\"*\"],\n",
    "                mode=\"text\",\n",
    "                showlegend=False\n",
    "            ), row=row, col=col)\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    height=1800,\n",
    "    width=1300,\n",
    "    title_text=\"Is Calib better than just scaling?\",\n",
    "    template=\"simple_white\",\n",
    "    showlegend=True,\n",
    "    font=dict(size=16, family=\"Arial\"),\n",
    "    margin=dict(t=150)\n",
    ")\n",
    "\n",
    "# Axis formatting\n",
    "for i in range(1, 5):\n",
    "    for j in range(1, 4):  # 3 columns\n",
    "        if j == 1:\n",
    "            model_b_label = model_name_map[\"scaled\"]\n",
    "        elif j == 2:\n",
    "            model_b_label = model_name_map[\"pt_calib\"]\n",
    "        else:\n",
    "            model_b_label = model_name_map[\"pt_calib\"]  # comparing scaled vs pt_calib\n",
    "        model_a_label = model_name_map[\"pretrained\"] if j in [1, 2] else model_name_map[\"scaled\"]\n",
    "\n",
    "        fig.update_yaxes(range=[0, 8], title_text=\"Euclidean Error (dva)\", row=i, col=j)\n",
    "        fig.update_xaxes(\n",
    "            tickvals=[0, 1],\n",
    "            ticktext=[model_a_label, model_b_label],\n",
    "            row=i, col=j\n",
    "        )\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepmreye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
